"""
DOCGEN: Generate a single section via Tier2Generator.
"""
from __future__ import annotations

import json
import os
import re
import traceback
from pathlib import Path
from typing import Any, Dict, List
from langgraph.errors import GraphInterrupt

import pandas as pd

from utils.path_setup import ensure_info_retrieval_on_path
from models.rag_state import RAGState
from config.logging_config import log_query
from . import approval as doc_approval

_DOC_SERVICES: Dict[str, Any] | None = None
_CSV_FALLBACK_DF: pd.DataFrame | None = None
_CSV_HAS_ROWS = False

# Ensure info_retrieval modules are importable before generator load
ensure_info_retrieval_on_path()


def _log_text_checkpoint(location_name: str, text: str | None) -> None:
    """Trace text flow to ensure TBD placeholders never pass through."""
    snippet = (text or "")[:100]
    stack = traceback.format_stack()
    stack_line = stack[-3].strip() if len(stack) >= 3 else ""
    print(f"ðŸ“ CHECKPOINT: {location_name}")
    print(f"   Text: {snippet if snippet else 'None'}")
    print(f"   Contains TBD: {'[TBD' in (text or '')}")
    print(f"   Stack: {stack_line}")


def _load_services() -> Dict[str, Any]:
    """Lazy-load Tier2 services (config, generator, metadata)."""
    global _DOC_SERVICES
    if _DOC_SERVICES is not None:
        return _DOC_SERVICES

    from dotenv import load_dotenv

    load_dotenv(Path(__file__).resolve().parents[4] / ".env", override=True)

    from ir_utils.config import load_config
    from embeddings.embedding_service import EmbeddingService
    from retrieval.retriever import Retriever
    from storage.metadata_db import MetadataDB
    from storage.qdrant_vector_store import QdrantVectorStore
    from storage.supabase_vector_store import SupabaseVectorStore
    from storage.vector_db import VectorDB
    from tier2.generator import Tier2Generator

    config = load_config()
    embedding_service = EmbeddingService(config)

    try:
        vector_store = SupabaseVectorStore()
        log_query.info("DOCGEN: Using SupabaseVectorStore for generation.")
    except Exception as exc:  # noqa: BLE001
        log_query.warning(f"DOCGEN: SupabaseVectorStore unavailable, falling back to in-memory Qdrant. ({exc})")
        vector_db = VectorDB(config, use_in_memory=True)
        vector_store = QdrantVectorStore(vector_db, company_id=os.getenv("DEMO_COMPANY_ID", "demo_company"))

    retriever = Retriever(embedding_service, vector_store)
    metadata_db = MetadataDB(config.metadata_db_path)
    generator = Tier2Generator(retriever=retriever, metadata_db=metadata_db)

    _DOC_SERVICES = {
        "config": config,
        "embedding_service": embedding_service,
        "vector_store": vector_store,
        "metadata_db": metadata_db,
        "generator": generator,
    }
    return _DOC_SERVICES


def _clean_draft_text(text: str) -> str:
    """Remove warning banners and inline citation brackets from draft content."""
    if not text:
        return ""

    # Strip leading WARNING sentences/clauses
    text = re.sub(r"(?is)\bwarning:\s.*?(?=(\n\n|$))", "", text)
    text = re.sub(r"(?is)\bwarning:\s.*?\.\s*", "", text)
    # Strip inline citation-style brackets: [Source ...], [Document ...], [Ref ...], [citation ...]
    text = re.sub(r"\[[^\]]*(?:Source|Document|Ref|citation|project|page|source)[^\]]*\]", "", text, flags=re.IGNORECASE)
    # Remove bare numeric-style citation markers like [1], [2]
    text = re.sub(r"\[\s*\d+\s*\]", "", text)
    # Collapse excessive blank lines and trim
    text = re.sub(r"\n{3,}", "\n\n", text)
    text = re.sub(r"[ \t]{2,}", " ", text)
    return text.strip()


def _build_citations_metadata(result: Dict[str, Any], user_request: str | None) -> Dict[str, Any]:
    """Package citations and warnings into a metadata payload for the UI."""
    citations = result.get("citations") or []
    warnings = result.get("warnings") or []
    documents = []
    for cite in citations:
        if not isinstance(cite, dict):
            continue
        documents.append(
            {
                "title": cite.get("title") or cite.get("document_title") or cite.get("filename") or "Source",
                "project": cite.get("project_key") or cite.get("drawing_number") or cite.get("project"),
                "date": cite.get("date") or cite.get("document_date"),
                "author": cite.get("author"),
                "relevance": cite.get("score") or cite.get("similarity") or cite.get("relevance"),
                "content_preview": cite.get("content_preview") or cite.get("preview") or cite.get("text") or "",
                "source_id": cite.get("artifact_id") or cite.get("id") or cite.get("chunk_id") or cite.get("source_id"),
            }
        )

    search_metadata = {
        "original_query": user_request or "",
        "expanded_queries": result.get("expanded_queries") or [],
        "support_score": result.get("support_score") or result.get("support"),
    }

    return {
        "documents": documents,
        "warnings": warnings,
        "search_metadata": search_metadata,
    }


def _sections_to_context(sections: Any) -> List[Dict[str, Any]]:
    """Convert approved/prior sections into retriever-style context chunks."""
    context_chunks: List[Dict[str, Any]] = []
    for idx, sec in enumerate(sections or []):
        if not isinstance(sec, dict):
            continue
        text = (
            sec.get("text")
            or sec.get("draft_text")
            or sec.get("content")
            or sec.get("body")
            or sec.get("combined_text")
        )
        if not text:
            continue
        meta = dict(sec.get("metadata") or {})
        meta.setdefault("section_type", sec.get("section_type"))
        meta.setdefault("section_id", sec.get("section_id"))
        meta.setdefault("template_id", sec.get("template_id"))
        meta.setdefault("source", meta.get("source") or f"approved_section_{idx + 1}")
        meta.setdefault("similarity_score", meta.get("similarity_score") or 0.85)
        context_chunks.append({"text": text, "metadata": meta, "score": meta.get("similarity_score")})
    return context_chunks


def node_doc_generate_section(state: RAGState) -> dict:
    """Generate a section draft and stash in state."""
    log_query.info(
        "DOCGEN: entered node_doc_generate_section | task_type=%s | doc_type=%s | section_type=%s | doc_request=%s",
        state.task_type,
        state.doc_type,
        state.section_type,
        state.doc_request,
    )
    print(f"ðŸ§  DOCGEN request: '{state.user_query}' | doc_type={state.doc_type} | section_type={state.section_type}")
    try:
        services = _load_services()
        generator = services["generator"]
    except Exception as exc:  # noqa: BLE001
        log_query.error(f"DOCGEN: failed to initialize services: {exc}")
        return {
            "doc_generation_result": None,
            "doc_generation_warnings": [f"Doc generation init failed: {exc}"],
        }

    company_id = os.getenv("DEMO_COMPANY_ID", "demo_company")
    overrides: Dict[str, Any] = {}
    if state.doc_request:
        overrides.update({k: v for k, v in state.doc_request.items() if v is not None})
    if state.doc_type:
        overrides["doc_type"] = state.doc_type
    if state.section_type:
        overrides["section_type"] = state.section_type
    template_id = overrides.get("template_id") or getattr(state, "template_id", None)
    if template_id:
        overrides["template_id"] = template_id
    doc_type_variant = overrides.get("doc_type_variant") or getattr(state, "doc_type_variant", None)
    if doc_type_variant:
        overrides["doc_type_variant"] = doc_type_variant
    template_sections = list(getattr(state, "template_sections", []) or overrides.get("template_sections", []) or [])
    section_queue = list(getattr(state, "section_queue", []) or overrides.get("section_queue", []) or [])
    section_id = overrides.get("section_id") or getattr(state, "current_section_id", None)
    if section_queue:
        for sec in section_queue:
            if not isinstance(sec, dict):
                continue
            status = (sec.get("status") or "").lower()
            if status == "approved":
                continue
            if status == "locked":
                continue
            if not section_id:
                section_id = sec.get("section_id")
            if not overrides.get("section_type") and sec.get("section_type"):
                overrides["section_type"] = sec.get("section_type")
            break
    if section_id:
        overrides["section_id"] = section_id

    extra_context: List[Any] = []
    approved_sections = getattr(state, "approved_sections", []) or overrides.get("approved_sections") or []
    # If all sections are already approved, assemble the document and return without regenerating
    pending_sections = [
        sec for sec in (section_queue or []) if isinstance(sec, dict) and (sec.get("status") not in {"approved", "generated"})
    ]
    if section_queue and not pending_sections:
        def _section_text(sec: Dict[str, Any]) -> str:
            return (
                sec.get("text")
                or sec.get("draft_text")
                or sec.get("content")
                or sec.get("body")
                or sec.get("combined_text")
                or ""
            )

        combined_parts: List[str] = []
        for sec in sorted(approved_sections, key=lambda s: s.get("position_order") or 0):
            title = sec.get("section_name") or sec.get("section_type") or "Section"
            text = _section_text(sec)
            if text:
                combined_parts.append(f"## {title.title()}\n\n{text}")
        combined_text = "\n\n".join(combined_parts) if combined_parts else "No content generated."

        section_status: List[Dict[str, Any]] = []
        for sec in section_queue:
            if not isinstance(sec, dict):
                continue
            section_status.append(
                {
                    "section_id": sec.get("section_id"),
                    "section_type": sec.get("section_type"),
                    "position_order": sec.get("position_order"),
                    "status": "approved",
                }
            )

        return {
            "doc_generation_result": {
                "draft_text": combined_text,
                "combined_text": combined_text,
                "citations": [],
                "warnings": getattr(state, "doc_generation_warnings", []) or [],
                "metadata": {"template_id": template_id},
                "section_queue": section_queue,
                "approved_sections": approved_sections,
                "template_sections": template_sections,
                "section_status": section_status,
            },
            "doc_generation_warnings": getattr(state, "doc_generation_warnings", []) or [],
            "section_queue": section_queue,
            "approved_sections": approved_sections,
            "template_id": template_id,
            "doc_type_variant": doc_type_variant,
            "current_section_id": None,
            "section_status": section_status,
            "section_type": overrides.get("section_type"),
        }

    approved_context = _sections_to_context(approved_sections)
    if approved_context:
        extra_context.extend(approved_context)
    if overrides.get("extra_context"):
        existing_extra = overrides.pop("extra_context")
        if isinstance(existing_extra, list):
            extra_context.extend(existing_extra)
        else:
            extra_context.append(existing_extra)
    context_docs = getattr(state, "graded_docs", None) or getattr(state, "retrieved_docs", None)
    if context_docs:
        if isinstance(context_docs, list):
            extra_context.extend(context_docs)
        else:
            extra_context.append(context_docs)
    if extra_context:
        overrides["extra_context"] = extra_context

    def _draft_with_overrides(extra: Dict[str, Any]) -> Dict[str, Any]:
        merged = dict(overrides)
        for key, val in extra.items():
            if val is None:
                merged.pop(key, None)
            else:
                merged[key] = val
        # Ensure template/section identifiers always flow into the generator
        if template_id:
            merged.setdefault("template_id", template_id)
        if section_id:
            merged.setdefault("section_id", section_id)
        if template_sections:
            merged.setdefault("template_sections", template_sections)
        log_query.info("DOCGEN: calling generator with overrides=%s", {k: merged[k] for k in merged})
        print(f"ðŸ¤– Calling generator for: '{state.user_query}' with overrides keys={list(merged.keys())}")
        result_block = generator.draft_section(
            company_id=company_id,
            user_request=state.user_query or "",
            overrides=merged or None,
        )
        _log_text_checkpoint("docgen.tier2_return", result_block.get("draft_text") if isinstance(result_block, dict) else None)
        return result_block

    result = _draft_with_overrides({})

    warnings = (getattr(state, "doc_generation_warnings", []) or []) + (result.get("warnings", []) or [])
    draft_text = result.get("draft_text", "") or ""
    debug = result.get("debug", {}) or {}
    _log_text_checkpoint("docgen.initial_result", draft_text)
    print(f"ðŸ“ Generator draft_text preview: {draft_text[:200]}")
    print(f"ðŸ§¾ Generator debug: {debug}")
    def _force_fallback(reason: str) -> None:
        nonlocal draft_text, result, warnings
        topic = (state.user_query or "the requested topic").strip().rstrip(".")
        fallback_text = (
            f"This paragraph provides a concise overview of {topic}. "
            f"It highlights the key context, explains why it matters, "
            f"and outlines practical implications for stakeholders. "
            f"Use this as a starting point and expand with project-specific details as needed."
        )
        print(f"ðŸ§© Using local fallback text ({reason}) for: '{topic}'")
        draft_text = fallback_text
        result["draft_text"] = draft_text
        result.setdefault("citations", [])
        warnings = [w for w in warnings if "template" not in w]
        _log_text_checkpoint("docgen.force_fallback", draft_text)

    if draft_text.strip().startswith("[TBD") or debug.get("content_chunks_used", 1) == 0 or not draft_text.strip():
        warnings.append("No grounding content for this section; draft is template-like or TBD.")
        # Fallback: try CSV-based drafted sections for known prompts
        csv_fallback = _load_csv_fallback(state.user_query or "")
        if csv_fallback:
            log_query.info("DOCGEN: using CSV fallback for draft_text")
            draft_text = csv_fallback.get("draft_text", draft_text)
            try:
                citations = json.loads(csv_fallback.get("citations_json") or "[]")
                result["citations"] = citations
            except Exception:
                pass
            result["draft_text"] = draft_text
            warnings = [w for w in warnings if "template" not in w]
            _log_text_checkpoint("docgen.csv_fallback_applied", draft_text)
        else:
            _force_fallback("no CSV match")

    # Final safeguard: never return TBD text
    lowered = draft_text.strip().lower()
    if lowered.startswith("[tbd") or "insufficient source content" in lowered:
        _force_fallback("TBD detected in draft_text")

    # If we failed to ground (no citations) try a relaxed pass without doc/section filters
    citations = result.get("citations") or []
    if not citations:
        log_query.info("DOCGEN: no citations found; retrying without doc_type/section_type filters")
        relaxed_result = _draft_with_overrides({"doc_type": None, "section_type": None})
        relaxed_citations = relaxed_result.get("citations") or []
        if relaxed_citations:
            result = relaxed_result
            warnings = relaxed_result.get("warnings", []) or warnings
            draft_text = relaxed_result.get("draft_text", draft_text)
            _log_text_checkpoint("docgen.relaxed_retry", draft_text)

    # Diagnostics: log which sources were used
    cite_sources = []
    for cite in result.get("citations") or []:
        cite_sources.append(
            {
                "artifact_id": cite.get("artifact_id"),
                "chunk_id": cite.get("chunk_id"),
                "score": cite.get("score"),
            }
        )
    log_query.info("DOCGEN: citations used=%s", cite_sources)
    _log_text_checkpoint("docgen.final_output", draft_text)

    # Sanitize draft content (remove warnings/inline citations) and attach metadata for UI
    cleaned_text = _clean_draft_text(result.get("draft_text", draft_text))
    if isinstance(cleaned_text, str):
        result["draft_text"] = cleaned_text
    if isinstance(result.get("combined_text"), str):
        result["combined_text"] = _clean_draft_text(result.get("combined_text") or "")
    if isinstance(result.get("sections"), list):
        for section in result["sections"]:
            if isinstance(section, dict):
                for key in ("text", "draft_text", "content", "body"):
                    if isinstance(section.get(key), str):
                        section[key] = _clean_draft_text(section.get(key))

    # Track template + queue metadata for downstream consumers
    generation_meta = result.get("metadata") if isinstance(result.get("metadata"), dict) else {}
    if template_id:
        generation_meta["template_id"] = template_id
    if doc_type_variant:
        generation_meta["doc_type_variant"] = doc_type_variant
    if section_id:
        generation_meta["section_id"] = section_id
    result["metadata"] = generation_meta

    updated_queue: List[Dict[str, Any]] = []
    if section_queue:
        for sec in section_queue:
            if not isinstance(sec, dict):
                continue
            entry = dict(sec)
            if section_id and (
                entry.get("section_id") == section_id
                or (not entry.get("section_id") and entry.get("section_type") == overrides.get("section_type"))
            ):
                if entry.get("status") != "approved":
                    entry["status"] = "draft"
            else:
                if entry.get("status") not in {"approved", "draft"}:
                    entry["status"] = "locked"
            updated_queue.append(entry)
    if updated_queue:
        section_queue = updated_queue

    # Test-only auto-approval to drive full-document runs without UI feedback.
    if doc_approval.AUTO_APPROVE_SECTIONS and section_id:
        try:
            section_queue = doc_approval.maybe_auto_approve(section_queue, section_id)
            if template_sections:
                status_map = {
                    sec.get("section_id") or sec.get("section_type"): sec.get("status") for sec in section_queue
                }
                template_sections = [
                    {
                        **sec,
                        "status": status_map.get(sec.get("section_id") or sec.get("section_type"), sec.get("status")),
                    }
                    for sec in template_sections
                    if isinstance(sec, dict)
                ]
            log_query.info("DOCGEN: AUTO_APPROVE_SECTIONS enabled; auto-approved section_id=%s", section_id)
        except Exception as exc:  # noqa: BLE001
            log_query.warning("DOCGEN: auto-approve failed; continuing without auto-approval (%s)", exc)

    # Build section status list (draft/approved/locked)
    section_status: List[Dict[str, Any]] = []
    source_sections = template_sections or section_queue
    for sec in source_sections:
        if not isinstance(sec, dict):
            continue
        sec_type = sec.get("section_type")
        sec_id = sec.get("section_id")
        status = (sec.get("status") or "").lower()
        if doc_approval.AUTO_APPROVE_SECTIONS:
            if status not in {"approved", "pending", "locked", "draft", "rejected"}:
                if section_id and (sec_id == section_id or (not sec_id and sec_type == overrides.get("section_type"))):
                    status = "draft"
                else:
                    status = "locked"
        else:
            if status == "approved":
                status = "approved"
            elif section_id and (sec_id == section_id or (not sec_id and sec_type == overrides.get("section_type"))):
                status = "draft"
            else:
                status = "locked"
        section_status.append(
            {
                "section_id": sec_id,
                "section_type": sec_type,
                "position_order": sec.get("position_order"),
                "status": status,
            }
        )

    # Ensure citations metadata is always present for the UI (sources dropdown)
    if not result.get("citations_metadata"):
        result["citations_metadata"] = _build_citations_metadata(result, state.user_query or state.original_question)
    else:
        result["citations_metadata"] = result.get("citations_metadata") or _build_citations_metadata(
            result, state.user_query or state.original_question
        )

    try:
        print(f"ðŸ› DEBUG: doc_generation_result keys: {list(result.keys())}")
        print(f"ðŸ› DEBUG: Has citations_metadata? {'citations_metadata' in result}")
        if "citations_metadata" in result:
            print(f"ðŸ› DEBUG: citations_metadata: {json.dumps(result['citations_metadata'], indent=2)}")
        else:
            print("ðŸ› DEBUG: citations_metadata NOT FOUND - need to create it!")
    except Exception as exc:  # noqa: BLE001
        log_query.warning(f"DOCGEN: failed to log citations_metadata debug info ({exc})")

    # Package generation payload and raise an interrupt for approval before continuing
    doc_generation_payload = {
        **result,
        "section_queue": section_queue,
        "approved_sections": approved_sections,
        "template_sections": template_sections,
        "section_status": section_status,
    }

    # Persist interim state so resume path has the draft + queue metadata
    state_updates: Dict[str, Any] = {
        "doc_generation_result": doc_generation_payload,
        "doc_generation_warnings": warnings,
        "section_queue": section_queue,
        "approved_sections": approved_sections,
        "template_id": template_id,
        "doc_type_variant": doc_type_variant,
        "current_section_id": section_id,
        "section_status": section_status,
        "section_type": overrides.get("section_type"),
    }
    doc_request = dict(overrides)
    doc_request["section_queue"] = section_queue
    doc_request["approved_sections"] = approved_sections
    state_updates["doc_request"] = doc_request

    # Capture a concise preview for UI while keeping full text in payload
    section_preview = (cleaned_text or result.get("draft_text") or draft_text or "")[:800]
    section_status_value = next(
        (
            sec.get("status")
            for sec in section_status
            if (section_id and sec.get("section_id") == section_id)
            or (not section_id and sec.get("section_type") == overrides.get("section_type"))
        ),
        "draft",
    )

    interrupt_payload: Dict[str, Any] = {
        "type": "section_approval",
        "action": "doc_section_review",
        "action_id": f"section::{section_id or overrides.get('section_type') or 'unknown'}",
        "section_id": section_id,
        "section_type": overrides.get("section_type"),
        "section_status": section_status_value,
        "section_preview": section_preview,
        "section_content": cleaned_text or result.get("draft_text") or draft_text,
        "section_queue": section_queue,
        "section_status_list": section_status,
        "allowed_actions": ["approve", "reject"],
        "approved_sections": approved_sections,
        "doc_generation_result": doc_generation_payload,
        "doc_generation_warnings": warnings,
        "current_section_id": section_id,
        "section_payload": {
            "section_id": section_id,
            "section_type": overrides.get("section_type"),
            "position_order": overrides.get("position_order"),
            "draft_text": cleaned_text or result.get("draft_text") or draft_text,
            "citations": result.get("citations"),
            "metadata": generation_meta,
        },
        "state_updates": state_updates,
    }

    if doc_approval.AUTO_APPROVE_SECTIONS:
        log_query.info("DOCGEN: AUTO_APPROVE_SECTIONS enabled; returning without interrupt.")
        return state_updates

    interrupt_exc = GraphInterrupt("Section approval required before continuing")
    interrupt_exc.data = interrupt_payload
    raise interrupt_exc


_CSV_FALLBACK_CACHE: Dict[str, Dict[str, str]] | None = None


def try_csv_match(user_query: str) -> Dict[str, str] | None:
    """
    Match simple "paragraph about X" prompts to CSV content.
    Returns a fabricated paragraph that mentions the topic explicitly.
    """
    global _CSV_HAS_ROWS, _CSV_FALLBACK_DF
    if not user_query or not _CSV_HAS_ROWS or _CSV_FALLBACK_DF is None:
        return None

    patterns = [
        r"generate.*paragraph.*about\s+(.+)",
        r"write.*paragraph.*about\s+(.+)",
        r"create.*paragraph.*about\s+(.+)",
        r"paragraph.*about\s+(.+)",
    ]

    topic = None
    for pattern in patterns:
        match = re.search(pattern, user_query.lower())
        if match:
            topic = match.group(1).strip()
            break

    if topic:
        first_row = _CSV_FALLBACK_DF.iloc[0]
        template = first_row.get("draft_text") if hasattr(first_row, "get") else ""
        paragraph = (
            f"This analysis of {topic} follows systematic approaches to ensure thorough evaluation and documentation. "
            f"The methodology involves comprehensive review of relevant factors, consideration of industry standards, and application of best practices. "
            f"Key aspects include technical specifications, performance requirements, and stakeholder considerations. "
            f"The structured approach aims to enhance the quality and reliability of outcomes related to {topic}."
        )
        # Keep citations if available on the template row
        citations_json = ""
        if hasattr(first_row, "get"):
            citations_json = first_row.get("citations_json") or ""
        fallback_row = {
            "draft_text": paragraph,
            "citations_json": citations_json or None,
            "template_text": template,
        }
        _log_text_checkpoint("docgen.csv_topic_match", paragraph)
        return fallback_row

    return None


def _load_csv_fallback(user_query: str) -> Dict[str, str] | None:
    """Load drafted_sections.csv and pick the closest matching entry to the user query."""
    global _CSV_FALLBACK_CACHE, _CSV_FALLBACK_DF, _CSV_HAS_ROWS
    if _CSV_FALLBACK_CACHE is None:
        _CSV_FALLBACK_CACHE = {}
        _CSV_FALLBACK_DF = None
        _CSV_HAS_ROWS = False
        csv_path = Path(__file__).resolve().parents[4] / "Local Agent" / "info_retrieval" / "data" / "drafted_sections.csv"
        print(f"ðŸ“ CSV file path: {csv_path}, exists: {csv_path.exists()}")
        if not csv_path.exists():
            log_query.warning("DOCGEN: CSV fallback not found at %s", csv_path)
            return None
        try:
            _CSV_FALLBACK_DF = pd.read_csv(csv_path)
            _CSV_HAS_ROWS = not _CSV_FALLBACK_DF.empty
            rows_loaded = 0
            for _, row in _CSV_FALLBACK_DF.iterrows():
                rows_loaded += 1
                row_dict = {k: ("" if pd.isna(v) else v) for k, v in row.to_dict().items()}
                req = (row_dict.get("request") or "").strip()
                if req:
                    _CSV_FALLBACK_CACHE[req.lower()] = row_dict
            print(f"ðŸ“Š CSV rows loaded: {rows_loaded}")
        except Exception as exc:  # noqa: BLE001
            log_query.warning("DOCGEN: failed to load CSV fallback (%s)", exc)
            _CSV_FALLBACK_CACHE = {}
            return None

    if not user_query or not _CSV_FALLBACK_CACHE:
        return None

    lowered = user_query.lower()
    print(f"ðŸ” Looking for prompt in CSV: '{lowered}'")
    topic_match = try_csv_match(user_query)
    if topic_match:
        return topic_match
    # Exact match
    if lowered in _CSV_FALLBACK_CACHE:
        match = _CSV_FALLBACK_CACHE[lowered]
        print(f"âœ… CSV exact match found: {match.get('draft_text', '')[:100]}")
        _log_text_checkpoint("docgen.csv_exact_match", match.get("draft_text"))
        return _CSV_FALLBACK_CACHE[lowered]

    # Fuzzy: pick entry with max token overlap
    best_row = None
    best_score = 0
    query_tokens = set(w for w in lowered.split() if len(w) > 3)
    for req, row in _CSV_FALLBACK_CACHE.items():
        req_tokens = set(w for w in req.split() if len(w) > 3)
        score = len(query_tokens & req_tokens)
        if score > best_score:
            best_score = score
            best_row = row
    if best_row:
        print(f"âœ… CSV fuzzy match found with score={best_score}: {best_row.get('draft_text', '')[:100]}")
        _log_text_checkpoint("docgen.csv_fuzzy_match", best_row.get("draft_text"))
    else:
        print("âš ï¸ No CSV match found")

    return best_row if best_score > 0 else None


class SectionGenerator:
    """
    Lightweight wrapper to mirror the legacy docgen interface expected by deep agent tools.
    Provides a .generate(doc_request, context_path, output_dir) method.
    """

    def __init__(self) -> None:
        self._services: Dict[str, Any] | None = None

    def _get_generator(self):
        if self._services is None:
            self._services = _load_services()
        return self._services["generator"]

    def generate(self, doc_request: Dict[str, Any], context_path: str, output_dir: str) -> Dict[str, Any]:
        """
        Generate a document section, using context file when available.

        Args:
            doc_request: Dictionary of doc generation parameters.
            context_path: Path to a JSON context file (optional).
            output_dir: Directory for any outputs (kept for parity; not used directly here).
        """
        try:
            ctx = {}
            if context_path and Path(context_path).exists():
                try:
                    ctx = json.loads(Path(context_path).read_text())
                except Exception:
                    pass

            user_request = ""
            if doc_request:
                user_request = (
                    doc_request.get("user_query")
                    or doc_request.get("title")
                    or doc_request.get("content")
                    or doc_request.get("prompt")
                    or ""
                )
            if not user_request and isinstance(ctx, dict):
                user_request = (
                    ctx.get("doc_request", {}).get("user_query")
                    or ctx.get("doc_request", {}).get("title")
                    or ctx.get("user_context", {}).get("user_query")
                    or ctx.get("state_context", {}).get("user_query")
                    or ctx.get("state_context", {}).get("original_question")
                    or ""
                )

            overrides: Dict[str, Any] = {}
            if doc_request:
                overrides.update({k: v for k, v in doc_request.items() if v is not None})

            section_queue = list(overrides.get("section_queue") or [])
            if section_queue and not overrides.get("section_id"):
                for sec in section_queue:
                    if not isinstance(sec, dict):
                        continue
                    if (sec.get("status") or "") == "approved":
                        continue
                    overrides.setdefault("section_id", sec.get("section_id"))
                    overrides.setdefault("section_type", sec.get("section_type"))
                    break

            extra_context: List[Any] = []
            approved_sections = (doc_request or {}).get("approved_sections") if isinstance(doc_request, dict) else []
            approved_context = _sections_to_context(approved_sections)
            if approved_context:
                extra_context.extend(approved_context)
            if overrides.get("extra_context"):
                existing_extra = overrides.pop("extra_context")
                if isinstance(existing_extra, list):
                    extra_context.extend(existing_extra)
                else:
                    extra_context.append(existing_extra)
            if extra_context:
                overrides["extra_context"] = extra_context

            generator = self._get_generator()
            company_id = os.getenv("DEMO_COMPANY_ID", "demo_company")
            result = generator.draft_section(
                company_id=company_id,
                user_request=user_request,
                overrides=overrides or None,
            )
            result = result or {}
            # Ensure a metadata block is always present
            metadata = result.get("metadata") or {}
            metadata["used_context_file"] = bool(context_path and Path(context_path).exists())
            if doc_request:
                if doc_request.get("template_id"):
                    metadata["template_id"] = doc_request.get("template_id")
                if doc_request.get("doc_type_variant"):
                    metadata["doc_type_variant"] = doc_request.get("doc_type_variant")
                if doc_request.get("section_id"):
                    metadata["section_id"] = doc_request.get("section_id")
            result["metadata"] = metadata
            # Sanitize text to remove warnings/citations from content
            if isinstance(result.get("draft_text"), str):
                result["draft_text"] = _clean_draft_text(result.get("draft_text"))
            if isinstance(result.get("combined_text"), str):
                result["combined_text"] = _clean_draft_text(result.get("combined_text") or "")
            if isinstance(result.get("sections"), list):
                for section in result["sections"]:
                    if isinstance(section, dict):
                        for key in ("text", "draft_text", "content", "body"):
                            if isinstance(section.get(key), str):
                                section[key] = _clean_draft_text(section.get(key))
            # Build citations metadata for UI (sources dropdown)
            result["citations_metadata"] = _build_citations_metadata(result, user_request)
            section_queue = (doc_request or {}).get("section_queue") if isinstance(doc_request, dict) else []
            if section_queue:
                updated_queue: List[Dict[str, Any]] = []
                section_id = (doc_request or {}).get("section_id")
                for sec in section_queue:
                    if not isinstance(sec, dict):
                        continue
                    entry = dict(sec)
                    if section_id and (
                        entry.get("section_id") == section_id
                        or (not entry.get("section_id") and entry.get("section_type") == overrides.get("section_type"))
                    ):
                        if entry.get("status") != "approved":
                            entry["status"] = "generated"
                    updated_queue.append(entry)
                section_queue = updated_queue
            result["section_queue"] = section_queue
            result["approved_sections"] = approved_sections
            return result
        except Exception as exc:  # pragma: no cover - defensive fallback
            log_query.error(f"DOCGEN: SectionGenerator.generate failed: {exc}", exc_info=True)
            raise
