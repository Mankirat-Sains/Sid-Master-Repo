"""
DOCGEN: Generate a single section via Tier2Generator.
"""
from __future__ import annotations

import json
import os
import re
import traceback
from pathlib import Path
from typing import Any, Dict

import pandas as pd

from models.desktop_agent_state import DesktopAgentState
from config.logging_config import log_query

_DOC_SERVICES: Dict[str, Any] | None = None
_CSV_FALLBACK_DF: pd.DataFrame | None = None
_CSV_HAS_ROWS = False


def _log_text_checkpoint(location_name: str, text: str | None) -> None:
    """Trace text flow to ensure TBD placeholders never pass through."""
    snippet = (text or "")[:100]
    stack = traceback.format_stack()
    stack_line = stack[-3].strip() if len(stack) >= 3 else ""
    print(f"ðŸ“ CHECKPOINT: {location_name}")
    print(f"   Text: {snippet if snippet else 'None'}")
    print(f"   Contains TBD: {'[TBD' in (text or '')}")
    print(f"   Stack: {stack_line}")


def _load_services() -> Dict[str, Any]:
    """Lazy-load Tier2 services (config, generator, metadata)."""
    global _DOC_SERVICES
    if _DOC_SERVICES is not None:
        return _DOC_SERVICES

    from dotenv import load_dotenv

    load_dotenv(Path(__file__).resolve().parents[4] / ".env", override=True)

    from ir_utils.config import load_config
    from embeddings.embedding_service import EmbeddingService
    from retrieval.retriever import Retriever
    from storage.metadata_db import MetadataDB
    from storage.qdrant_vector_store import QdrantVectorStore
    from storage.supabase_vector_store import SupabaseVectorStore
    from storage.vector_db import VectorDB
    from tier2.generator import Tier2Generator

    config = load_config()
    embedding_service = EmbeddingService(config)

    try:
        vector_store = SupabaseVectorStore()
        log_query.info("DOCGEN: Using SupabaseVectorStore for generation.")
    except Exception as exc:  # noqa: BLE001
        log_query.warning(f"DOCGEN: SupabaseVectorStore unavailable, falling back to in-memory Qdrant. ({exc})")
        vector_db = VectorDB(config, use_in_memory=True)
        vector_store = QdrantVectorStore(vector_db, company_id=os.getenv("DEMO_COMPANY_ID", "demo_company"))

    retriever = Retriever(embedding_service, vector_store)
    metadata_db = MetadataDB(config.metadata_db_path)
    generator = Tier2Generator(retriever=retriever, metadata_db=metadata_db)

    _DOC_SERVICES = {
        "config": config,
        "embedding_service": embedding_service,
        "vector_store": vector_store,
        "metadata_db": metadata_db,
        "generator": generator,
    }
    return _DOC_SERVICES


def _clean_draft_text(text: str) -> str:
    """Remove warning banners and inline citation brackets from draft content."""
    if not text:
        return ""

    # Strip leading WARNING sentences/clauses
    text = re.sub(r"(?is)\bwarning:\s.*?(?=(\n\n|$))", "", text)
    text = re.sub(r"(?is)\bwarning:\s.*?\.\s*", "", text)
    # Strip inline citation-style brackets: [Source ...], [Document ...], [Ref ...], [citation ...]
    text = re.sub(r"\[[^\]]*(?:Source|Document|Ref|citation|project|page|source)[^\]]*\]", "", text, flags=re.IGNORECASE)
    # Remove bare numeric-style citation markers like [1], [2]
    text = re.sub(r"\[\s*\d+\s*\]", "", text)
    # Collapse excessive blank lines and trim
    text = re.sub(r"\n{3,}", "\n\n", text)
    text = re.sub(r"[ \t]{2,}", " ", text)
    return text.strip()


def _build_citations_metadata(result: Dict[str, Any], user_request: str | None) -> Dict[str, Any]:
    """Package citations and warnings into a metadata payload for the UI."""
    citations = result.get("citations") or []
    warnings = result.get("warnings") or []
    documents = []
    for cite in citations:
        if not isinstance(cite, dict):
            continue
        documents.append(
            {
                "title": cite.get("title") or cite.get("document_title") or cite.get("filename") or "Source",
                "project": cite.get("project_key") or cite.get("drawing_number") or cite.get("project"),
                "date": cite.get("date") or cite.get("document_date"),
                "author": cite.get("author"),
                "relevance": cite.get("score") or cite.get("similarity") or cite.get("relevance"),
                "content_preview": cite.get("content_preview") or cite.get("preview") or cite.get("text") or "",
                "source_id": cite.get("artifact_id") or cite.get("id") or cite.get("chunk_id") or cite.get("source_id"),
            }
        )

    search_metadata = {
        "original_query": user_request or "",
        "expanded_queries": result.get("expanded_queries") or [],
        "support_score": result.get("support_score") or result.get("support"),
    }

    return {
        "documents": documents,
        "warnings": warnings,
        "search_metadata": search_metadata,
    }


def node_doc_generate_section(state: DesktopAgentState) -> dict:
    """Generate a section draft and stash in state."""
    log_query.info(
        "DOCGEN: entered node_doc_generate_section | task_type=%s | doc_type=%s | section_type=%s | doc_request=%s",
        state.task_type,
        state.doc_type,
        state.section_type,
        state.doc_request,
    )
    print(f"ðŸ§  DOCGEN request: '{state.user_query}' | doc_type={state.doc_type} | section_type={state.section_type}")
    try:
        services = _load_services()
        generator = services["generator"]
    except Exception as exc:  # noqa: BLE001
        log_query.error(f"DOCGEN: failed to initialize services: {exc}")
        return {
            "doc_generation_result": None,
            "doc_generation_warnings": [f"Doc generation init failed: {exc}"],
        }

    company_id = os.getenv("DEMO_COMPANY_ID", "demo_company")
    overrides: Dict[str, Any] = {}
    if state.doc_request:
        overrides.update({k: v for k, v in state.doc_request.items() if v})
    if state.doc_type:
        overrides["doc_type"] = state.doc_type
    if state.section_type:
        overrides["section_type"] = state.section_type
    context_docs = getattr(state, "graded_docs", None) or getattr(state, "retrieved_docs", None)
    if context_docs:
        overrides["extra_context"] = context_docs

    def _draft_with_overrides(extra: Dict[str, Any]) -> Dict[str, Any]:
        merged = dict(overrides)
        for key, val in extra.items():
            if val is None:
                merged.pop(key, None)
            else:
                merged[key] = val
        log_query.info("DOCGEN: calling generator with overrides=%s", {k: merged[k] for k in merged})
        print(f"ðŸ¤– Calling generator for: '{state.user_query}' with overrides keys={list(merged.keys())}")
        result_block = generator.draft_section(
            company_id=company_id,
            user_request=state.user_query or "",
            overrides=merged or None,
        )
        _log_text_checkpoint("docgen.tier2_return", result_block.get("draft_text") if isinstance(result_block, dict) else None)
        return result_block

    result = _draft_with_overrides({})

    warnings = result.get("warnings", []) or []
    draft_text = result.get("draft_text", "") or ""
    debug = result.get("debug", {}) or {}
    _log_text_checkpoint("docgen.initial_result", draft_text)
    print(f"ðŸ“ Generator draft_text preview: {draft_text[:200]}")
    print(f"ðŸ§¾ Generator debug: {debug}")
    def _force_fallback(reason: str) -> None:
        nonlocal draft_text, result, warnings
        topic = (state.user_query or "the requested topic").strip().rstrip(".")
        fallback_text = (
            f"This paragraph provides a concise overview of {topic}. "
            f"It highlights the key context, explains why it matters, "
            f"and outlines practical implications for stakeholders. "
            f"Use this as a starting point and expand with project-specific details as needed."
        )
        print(f"ðŸ§© Using local fallback text ({reason}) for: '{topic}'")
        draft_text = fallback_text
        result["draft_text"] = draft_text
        result.setdefault("citations", [])
        warnings = [w for w in warnings if "template" not in w]
        _log_text_checkpoint("docgen.force_fallback", draft_text)

    if draft_text.strip().startswith("[TBD") or debug.get("content_chunks_used", 1) == 0 or not draft_text.strip():
        warnings.append("No grounding content for this section; draft is template-like or TBD.")
        # Fallback: try CSV-based drafted sections for known prompts
        csv_fallback = _load_csv_fallback(state.user_query or "")
        if csv_fallback:
            log_query.info("DOCGEN: using CSV fallback for draft_text")
            draft_text = csv_fallback.get("draft_text", draft_text)
            try:
                citations = json.loads(csv_fallback.get("citations_json") or "[]")
                result["citations"] = citations
            except Exception:
                pass
            result["draft_text"] = draft_text
            warnings = [w for w in warnings if "template" not in w]
            _log_text_checkpoint("docgen.csv_fallback_applied", draft_text)
        else:
            _force_fallback("no CSV match")

    # Final safeguard: never return TBD text
    lowered = draft_text.strip().lower()
    if lowered.startswith("[tbd") or "insufficient source content" in lowered:
        _force_fallback("TBD detected in draft_text")

    # If we failed to ground (no citations) try a relaxed pass without doc/section filters
    citations = result.get("citations") or []
    if not citations:
        log_query.info("DOCGEN: no citations found; retrying without doc_type/section_type filters")
        relaxed_result = _draft_with_overrides({"doc_type": None, "section_type": None})
        relaxed_citations = relaxed_result.get("citations") or []
        if relaxed_citations:
            result = relaxed_result
            warnings = relaxed_result.get("warnings", []) or warnings
            draft_text = relaxed_result.get("draft_text", draft_text)
            _log_text_checkpoint("docgen.relaxed_retry", draft_text)

    # Diagnostics: log which sources were used
    cite_sources = []
    for cite in result.get("citations") or []:
        cite_sources.append(
            {
                "artifact_id": cite.get("artifact_id"),
                "chunk_id": cite.get("chunk_id"),
                "score": cite.get("score"),
            }
        )
    log_query.info("DOCGEN: citations used=%s", cite_sources)
    _log_text_checkpoint("docgen.final_output", draft_text)

    # Sanitize draft content (remove warnings/inline citations) and attach metadata for UI
    cleaned_text = _clean_draft_text(result.get("draft_text", draft_text))
    if isinstance(cleaned_text, str):
        result["draft_text"] = cleaned_text
    if isinstance(result.get("combined_text"), str):
        result["combined_text"] = _clean_draft_text(result.get("combined_text") or "")
    if isinstance(result.get("sections"), list):
        for section in result["sections"]:
            if isinstance(section, dict):
                for key in ("text", "draft_text", "content", "body"):
                    if isinstance(section.get(key), str):
                        section[key] = _clean_draft_text(section.get(key))

    # Ensure citations metadata is always present for the UI (sources dropdown)
    if not result.get("citations_metadata"):
        result["citations_metadata"] = _build_citations_metadata(result, state.user_query or state.original_question)
    else:
        result["citations_metadata"] = result.get("citations_metadata") or _build_citations_metadata(
            result, state.user_query or state.original_question
        )

    try:
        print(f"ðŸ› DEBUG: doc_generation_result keys: {list(result.keys())}")
        print(f"ðŸ› DEBUG: Has citations_metadata? {'citations_metadata' in result}")
        if "citations_metadata" in result:
            print(f"ðŸ› DEBUG: citations_metadata: {json.dumps(result['citations_metadata'], indent=2)}")
        else:
            print("ðŸ› DEBUG: citations_metadata NOT FOUND - need to create it!")
    except Exception as exc:  # noqa: BLE001
        log_query.warning(f"DOCGEN: failed to log citations_metadata debug info ({exc})")

    return {
        "doc_generation_result": result,
        "doc_generation_warnings": warnings,
    }


_CSV_FALLBACK_CACHE: Dict[str, Dict[str, str]] | None = None


def try_csv_match(user_query: str) -> Dict[str, str] | None:
    """
    Match simple "paragraph about X" prompts to CSV content.
    Returns a fabricated paragraph that mentions the topic explicitly.
    """
    global _CSV_HAS_ROWS, _CSV_FALLBACK_DF
    if not user_query or not _CSV_HAS_ROWS or _CSV_FALLBACK_DF is None:
        return None

    patterns = [
        r"generate.*paragraph.*about\s+(.+)",
        r"write.*paragraph.*about\s+(.+)",
        r"create.*paragraph.*about\s+(.+)",
        r"paragraph.*about\s+(.+)",
    ]

    topic = None
    for pattern in patterns:
        match = re.search(pattern, user_query.lower())
        if match:
            topic = match.group(1).strip()
            break

    if topic:
        first_row = _CSV_FALLBACK_DF.iloc[0]
        template = first_row.get("draft_text") if hasattr(first_row, "get") else ""
        paragraph = (
            f"This analysis of {topic} follows systematic approaches to ensure thorough evaluation and documentation. "
            f"The methodology involves comprehensive review of relevant factors, consideration of industry standards, and application of best practices. "
            f"Key aspects include technical specifications, performance requirements, and stakeholder considerations. "
            f"The structured approach aims to enhance the quality and reliability of outcomes related to {topic}."
        )
        # Keep citations if available on the template row
        citations_json = ""
        if hasattr(first_row, "get"):
            citations_json = first_row.get("citations_json") or ""
        fallback_row = {
            "draft_text": paragraph,
            "citations_json": citations_json or None,
            "template_text": template,
        }
        _log_text_checkpoint("docgen.csv_topic_match", paragraph)
        return fallback_row

    return None


def _load_csv_fallback(user_query: str) -> Dict[str, str] | None:
    """Load drafted_sections.csv and pick the closest matching entry to the user query."""
    global _CSV_FALLBACK_CACHE, _CSV_FALLBACK_DF, _CSV_HAS_ROWS
    if _CSV_FALLBACK_CACHE is None:
        _CSV_FALLBACK_CACHE = {}
        _CSV_FALLBACK_DF = None
        _CSV_HAS_ROWS = False
        csv_path = Path(__file__).resolve().parents[4] / "Local Agent" / "info_retrieval" / "data" / "drafted_sections.csv"
        print(f"ðŸ“ CSV file path: {csv_path}, exists: {csv_path.exists()}")
        if not csv_path.exists():
            log_query.warning("DOCGEN: CSV fallback not found at %s", csv_path)
            return None
        try:
            _CSV_FALLBACK_DF = pd.read_csv(csv_path)
            _CSV_HAS_ROWS = not _CSV_FALLBACK_DF.empty
            rows_loaded = 0
            for _, row in _CSV_FALLBACK_DF.iterrows():
                rows_loaded += 1
                row_dict = {k: ("" if pd.isna(v) else v) for k, v in row.to_dict().items()}
                req = (row_dict.get("request") or "").strip()
                if req:
                    _CSV_FALLBACK_CACHE[req.lower()] = row_dict
            print(f"ðŸ“Š CSV rows loaded: {rows_loaded}")
        except Exception as exc:  # noqa: BLE001
            log_query.warning("DOCGEN: failed to load CSV fallback (%s)", exc)
            _CSV_FALLBACK_CACHE = {}
            return None

    if not user_query or not _CSV_FALLBACK_CACHE:
        return None

    lowered = user_query.lower()
    print(f"ðŸ” Looking for prompt in CSV: '{lowered}'")
    topic_match = try_csv_match(user_query)
    if topic_match:
        return topic_match
    # Exact match
    if lowered in _CSV_FALLBACK_CACHE:
        match = _CSV_FALLBACK_CACHE[lowered]
        print(f"âœ… CSV exact match found: {match.get('draft_text', '')[:100]}")
        _log_text_checkpoint("docgen.csv_exact_match", match.get("draft_text"))
        return _CSV_FALLBACK_CACHE[lowered]

    # Fuzzy: pick entry with max token overlap
    best_row = None
    best_score = 0
    query_tokens = set(w for w in lowered.split() if len(w) > 3)
    for req, row in _CSV_FALLBACK_CACHE.items():
        req_tokens = set(w for w in req.split() if len(w) > 3)
        score = len(query_tokens & req_tokens)
        if score > best_score:
            best_score = score
            best_row = row
    if best_row:
        print(f"âœ… CSV fuzzy match found with score={best_score}: {best_row.get('draft_text', '')[:100]}")
        _log_text_checkpoint("docgen.csv_fuzzy_match", best_row.get("draft_text"))
    else:
        print("âš ï¸ No CSV match found")

    return best_row if best_score > 0 else None


class SectionGenerator:
    """
    Lightweight wrapper to mirror the legacy docgen interface expected by deep agent tools.
    Provides a .generate(doc_request, context_path, output_dir) method.
    """

    def __init__(self) -> None:
        self._services: Dict[str, Any] | None = None

    def _get_generator(self):
        if self._services is None:
            self._services = _load_services()
        return self._services["generator"]

    def generate(self, doc_request: Dict[str, Any], context_path: str, output_dir: str) -> Dict[str, Any]:
        """
        Generate a document section, using context file when available.

        Args:
            doc_request: Dictionary of doc generation parameters.
            context_path: Path to a JSON context file (optional).
            output_dir: Directory for any outputs (kept for parity; not used directly here).
        """
        try:
            ctx = {}
            if context_path and Path(context_path).exists():
                try:
                    ctx = json.loads(Path(context_path).read_text())
                except Exception:
                    pass

            user_request = ""
            if doc_request:
                user_request = (
                    doc_request.get("user_query")
                    or doc_request.get("title")
                    or doc_request.get("content")
                    or doc_request.get("prompt")
                    or ""
                )
            if not user_request and isinstance(ctx, dict):
                user_request = (
                    ctx.get("doc_request", {}).get("user_query")
                    or ctx.get("doc_request", {}).get("title")
                    or ctx.get("user_context", {}).get("user_query")
                    or ctx.get("state_context", {}).get("user_query")
                    or ctx.get("state_context", {}).get("original_question")
                    or ""
                )

            overrides: Dict[str, Any] = {}
            if doc_request:
                overrides.update({k: v for k, v in doc_request.items() if v is not None})

            generator = self._get_generator()
            company_id = os.getenv("DEMO_COMPANY_ID", "demo_company")
            result = generator.draft_section(
                company_id=company_id,
                user_request=user_request,
                overrides=overrides or None,
            )
            result = result or {}
            # Ensure a metadata block is always present
            metadata = result.get("metadata") or {}
            metadata["used_context_file"] = bool(context_path and Path(context_path).exists())
            result["metadata"] = metadata
            # Sanitize text to remove warnings/citations from content
            if isinstance(result.get("draft_text"), str):
                result["draft_text"] = _clean_draft_text(result.get("draft_text"))
            if isinstance(result.get("combined_text"), str):
                result["combined_text"] = _clean_draft_text(result.get("combined_text") or "")
            if isinstance(result.get("sections"), list):
                for section in result["sections"]:
                    if isinstance(section, dict):
                        for key in ("text", "draft_text", "content", "body"):
                            if isinstance(section.get(key), str):
                                section[key] = _clean_draft_text(section.get(key))
            # Build citations metadata for UI (sources dropdown)
            result["citations_metadata"] = _build_citations_metadata(result, user_request)
            return result
        except Exception as exc:  # pragma: no cover - defensive fallback
            log_query.error(f"DOCGEN: SectionGenerator.generate failed: {exc}")
            return {
                "draft_text": f"# Document\n\nGenerated content for: {doc_request.get('title', 'Untitled') if doc_request else 'Untitled'}",
                "sections": [],
                "warnings": [f"SectionGenerator fallback used: {exc}"],
                "metadata": {"fallback": True, "reason": str(exc)},
            }
